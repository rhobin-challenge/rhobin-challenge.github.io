<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>2nd RHOBIN Workshop@CVPR24</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link href="data/default.css" rel="stylesheet" type="text/css" />
    <link rel="icon" type="image/png" href="./data/rhobin-logo.png" />
    <meta property='og:title' content='RHOBIN Workshop: Reconstruction of Human-Object Interactions @ CVPR24'/>
    <meta property='og:url' content='https://rhobin-challenge.github.io/' />
    <meta property="og:type" content="website" />
  </head>


  <body>
    <div id="header">
      <div id="logo">
	<h1>
		<center>
	    	 <span style="font-size:50%;color:#777;font-weight:normal">The second Workshop on</span><br>
         Reconstruction of Human-Object Interactions (RHOBIN)<br>
  		</center>
	</h1><br>
</center>
</h1><br>
<div class="my-image-box-header">
 <center><img src="./data/rhobin-logo-no-bg.png" alt="rhobin-logo" width="128" height="168">
</center>
  
</div>
  <h2>
    <center>
      <span style="font-size:92%;color:#777;font-weight:normal">June 17, 13<sup>25</sup> - 18<sup>00</sup> @
          <a href="https://cvpr2024.thecvf.com/" target="_blank">CVPR 2024</a>,Seattle WA, USA</span><br>
      <span style="font-size:130%;color:#777;font-weight:bold">Summit 427 @ Seattle Convention Center</span>
    </center>
	</h2><br>
	</div>
  
    <div id="menu">
    <center>
      <ul>
        <li class="first"><a href="./index.html" accesskey="1">Home</a></li>
      </ul>
    </center>
</div>

<button onclick="topFunction()" id="myBtn" title="Go to top">Top</button>

<script>
//Get the button
var mybutton = document.getElementById("myBtn");

// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
      if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
              mybutton.style.display = "block";
                } else {
                        mybutton.style.display = "none";
                          }
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
      document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
}
</script>


<div id="content">
  <div id="tz_select">
     <p><h2 style="color:rgb(188, 131, 9);">Seattle Time (PDT)</h2></p>
  </div>
<!-- <p>
<ul>
<li>
    Here is <a href="https://live.allintheloop.net/App/ortra/ortraECCV2022" target="_blank">the ECCV Platform</a>.
</li>
<li>
    Please log in using your ECCV credentials, click "Workshops", then "Oct 24", find our workshop and click "Join Now".
</li>
</ul>
</p> -->


<table class="schedule" id="program">
  <tr class="row_type_tt">
    <td width="80px">
	    <b style="color:white;">Start</b>
    </td>
    <td width="80px">
	   <b style="color:white;">End</b>
    </td>
    <td>
	    <b style="color:white;">Event</b>
    </td>
  </tr>
  
  <tr class="row_type_C">
    <td> <span> 17 June 2024 13:25:00 PDT </span></td>
    <td> <span> 17 June 2024 13:30:00 PDT </span></td>
    <td>
        <p class="poster_title">Welcome and Introductions</p>
        Workshop Organizers
    </td>
  </tr>

  <tr class="row_type_B">
    <td> <span> 17 June 2024 13:30:00 PDT</span></td>
    <td> <span> 17 June 2024 14:00:00 PDT</span></td>
    <td>
      <table style="width:100%"><tr>
        <td style="border:none;width:20%">
          <a href="https://geopavlakos.github.io/" target="_blank">
            <img alt src="data/georgios_pavlakos.jpg" height="140"/>
          </a>Georgios Pavlakos<br>University of Texas, Austin</td>
        <td style="border:none;width:80%">
          <p class="poster_title">TBA</p>
          <p class="poster_abstract">
            TBA
          </p>
        </td>
      </tr></table>
    </td>
  </tr>

  <tr class="row_type_A">
    <td> <span> 17 June 2024 14:00:00 PDT</span></td>
    <td> <span> 17 June 2024 14:30:00 PDT</span></td>
      <td>
          <table style="width:100%"><tr>
            <td style="border:none;width:20%">
              <a href="http://www.cs.columbia.edu/~vondrick/" target="_blank">
                <img alt src="data/carl_vondrick.jpg" height="140"/>
              </a>Carl Vondrick<br>Columbia University</td>
            <td style="border:none;width:20%">
              <a href="https://ruoshiliu.github.io/" target="_blank">
                <img alt src="data/ruoshi_liu.jpg" height="140"/>
              </a>Ruoshi Liu<br>Columbia University</td>
            <td style="border:none;width:80%"><p class="poster_title">Bridging the Gap: Harnessing Human Knowledge for Robotic Manipulation</p>
                  <p class="poster_abstract">
                      The internet is a treasure trove of data showcasing human-object interactions, offering rich knowledge for robotic object manipulation.
                      However, a significant challenge remains: how can we translate this wealth of knowledge into practical applications for robotic systems,
                      given the differences in physical capabilities and embodiments between humans and robots? In this talk, I will unveil innovative strategies
                      to bridge this embodiment gap, enabling robots to perform complex object manipulations by learning from human behaviors. Discover how these
                      cutting-edge techniques are revolutionizing robotic manipulation in real-world scenarios.
                  </p>
            </td>
          </tr></table>
      </td>
  </tr>

 <tr class="row_type_B">
    <td> <span> 17 June 2024 14:30:00 PDT</span></td>
    <td> <span> 17 June 2024 15:15:00 PDT</span></td>
    <td>
        <table style="width:100%"><tr>
          <td style="border:none;width:20%">
            <a href="" target="_blank"> <img alt src="data/" height="140"/></a>
          </td>
          <td style="border:none;width:80%"><p class="poster_title">Presentations of the Rhobin Challenge results given by the winners<br></td></tr></table>
    </td>
  </tr>


 <tr class="row_type_F">
    <td> <span> 17 June 2024 15:15:00 PDT</span></td>
    <td> <span> 17 June 2024 16:00:00 PDT</span></td>
    <td>
        <table style="width:100%"><tr><td style="border:none;width:20%"><a href="" target="_blank"> <img alt src="data/" height="140"/></a></td>
                <td style="border:none;width:80%"><p class="poster_title">Coffee Break & Posters<br></td></tr></table>
    </td>
  </tr>

  <tr class="row_type_B">
    <td> <span> 17 June 2024 16:00:00 PDT</span></td>
    <td> <span> 17 June 2024 16:30:00 PDT</span></td>
    <td>
      <table style="width:100%"><tr>
        <td style="border:none;width:20%">
          <a href="https://ps.is.mpg.de/person/black" target="_blank">
            <img alt src="data/michael_black.jpg" height="140"/>
          </a>Michael Black<br>MPI-IS, TÃ¼bingen<br>Meshcapade</td>
        <td style="border:none;width:80%">
          <p class="poster_title">TBA</p>
          <p class="poster_abstract">
            TBA
          </p>
        </td>
      </tr></table>

    </td>
  </tr>

  <tr class="row_type_A">
    <td> <span> 17 June 2024 16:30:00 PDT</span></td>
    <td> <span> 17 June 2024 17:00:00 PDT</span></td>
    <td>
        <table style="width:100%"><tr>
          <td style="border:none;width:20%">
            <a href="https://www.3dunderstanding.org/" target="_blank">
              <img alt src="data/angela_dai.jpg" height="140"/>
            </a>Angela Dai <br>TUM, Munich</td>
        <td style="border:none;width:80%">
          <p class="poster_title">Human-centric 3D Scenes</p>
          <p class="poster_abstract">
            Understanding human interactions within 3D scenes is crucial for many applications, including robotics, virtual reality, and animation.
              However, limited ground truth 3D/4D data of human interactions makes such interaction understanding and modeling very challenging.
              We first propose to model dynamic human-object interactions through a contact-guided diffusion formulation, to enable text-guided human-object interaction synthesis.
              In order to achieve wide generality, we then propose to distill knowledge from powerful vision-language models to inform 3D human-scene interaction synthesis
              in a new zero-shot formulation. We hope this will pave the way for more realistic, generalized paradigms for interaction analysis and synthesis.
          </p>
        </td>
      </tr></table>
    </td>
  </tr>

  <tr class="row_type_B">
    <td> <span> 17 June 2024 17:00:00 PDT</span></td>
    <td> <span> 17 June 2024 17:30:00 PDT</span></td>
      <td>
          <table style="width:100%"><tr>
            <td style="border:none;width:20%">
              <a href="https://dimadamen.github.io/" target="_blank">
                <img alt src="data/dima_damen.jpg" width="140"/>
              </a>Dima Damen<br>University of Bristol<br>Google DeepMind</td>
            <td style="border:none;width:80%"><p class="poster_title">Understanding and Reconstructing Hand-Object Interactions from Egocentric Videos</p>
              <p class="poster_abstract">
                  TBA
              </p>
            </td>
          </tr></table>
      </td>
  </tr>

  <tr class="row_type_A">
    <td> <span> 17 June 2024 17:30:00 PDT</span></td>
    <td> <span> 17 June 2024 18:00:00 PDT</span></td>
    <td> <p class="poster_title">Panel discussion</p> </td>
  </tr>
</table>

<h2 id="contact">Contact Info</h2>
<p>E-mail: 
<a href="mailto:rhobinchallenge@gmail.com" target="_blank">rhobinchallenge@gmail.com</a>
</p>

<h2 id="acknowledgements">Acknowledgements</h2>
<p>Website template borrowed from: 
<a href="https://futurecv.github.io/" target="_blank">https://futurecv.github.io/</a>
(Thanks to <a href="https://www.cs.cmu.edu/~dpathak/" target="_blank">Deepak Pathak</a>)
</p>

<div style="clear: both;">&nbsp;</div>
</div><br><br>

</body>
</html>
